
===== Cartella Consumer =====
--- ./Consumer/Dockerfile ---
FROM python:3.11-slim

WORKDIR /app
COPY consumer.py requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt

CMD ["python", "consumer.py"]
-----------------------------
--- ./Consumer/consumer.py ---
from kafka import KafkaConsumer
from pymongo import MongoClient
from pymongo.errors import ConnectionFailure, OperationFailure
from datetime import datetime
import json, os, time

# Configurazione Kafka
KAFKA_BOOTSTRAP = os.getenv("KAFKA_BOOTSTRAP")
SASL_USERNAME = os.getenv("SASL_USERNAME")
SASL_PASSWORD = os.getenv("SASL_PASSWORD")
KAFKA_CA = "/etc/ssl/certs/kafka/ca.crt"

# Topic da consumare
TOPICS = ["sensor-telemetry", "sensor-alerts"]

# Configurazione MongoDB da ConfigMap e Secret
MONGO_HOST = os.getenv("MONGO_HOST")
MONGO_PORT = os.getenv("MONGO_PORT")
MONGO_DATABASE = os.getenv("MONGO_DATABASE")
MONGO_USER = os.getenv("MONGO_USER")
MONGO_PASSWORD = os.getenv("MONGO_PASSWORD")
MONGO_AUTH_SOURCE = os.getenv("MONGO_AUTH_SOURCE")

MONGO_URI = f"mongodb://{MONGO_USER}:{MONGO_PASSWORD}@{MONGO_HOST}:{MONGO_PORT}/{MONGO_DATABASE}?authSource={MONGO_AUTH_SOURCE}"

# Inizializzazione MongoDB con retry logic
def init_mongodb(max_retries=5, retry_delay=5):
    """Inizializza connessione MongoDB con retry automatico"""
    for attempt in range(1, max_retries + 1):
        try:
            client = MongoClient(MONGO_URI, serverSelectionTimeoutMS=5000)
            client.admin.command('ping')
            print(f"[✓] Connesso a MongoDB ({MONGO_HOST}:{MONGO_PORT})", flush=True)
            return client[MONGO_DATABASE].sensor_data
        except ConnectionFailure as e:
            print(f"[WARN] Tentativo {attempt}/{max_retries} fallito: {e}", flush=True)
            if attempt < max_retries:
                time.sleep(retry_delay)
            else:
                print("[ERROR] MongoDB non raggiungibile. Consumer termina.", flush=True)
                raise

collection = init_mongodb()

# Funzione helper per convertire la data
def fix_timestamp(event):
    if "timestamp" in event and isinstance(event["timestamp"], str):
        try:
            event["timestamp"] = datetime.fromisoformat(event["timestamp"])
        except ValueError:
            print(f"[WARN] Formato data non valido: {event['timestamp']}", flush=True)
    return event

# Funzione helper per inserimento sicuro
def safe_insert(event, event_description):
    """Inserisce evento in MongoDB con gestione errori"""
    event["_ingest_ts"] = datetime.utcnow()
    try:
        collection.insert_one(event)
        print(f"[✓] {event_description}", flush=True)
        return True
    except OperationFailure as e:
        print(f"[ERROR] Inserimento fallito ({event_description}): {e}", flush=True)
        return False
    except Exception as e:
        print(f"[ERROR] Errore inatteso ({event_description}): {e}", flush=True)
        return False

def handle_boot(event):
    event = fix_timestamp(event)
    desc = f"[BOOT] Device {event.get('device_id')} attivo in zona {event.get('zone_id')}"
    return safe_insert(event, desc)

def handle_telemetry(event):
    event = fix_timestamp(event)
    desc = f"[TELEMETRY] Device {event.get('device_id')} -> Temp: {event.get('temperature')}°C, Hum: {event.get('humidity')}%"
    return safe_insert(event, desc)

def handle_firmware_update(event):
    event = fix_timestamp(event)
    desc = f"[UPDATE] Device {event.get('device_id')} aggiornamento a {event.get('update_to')}"
    return safe_insert(event, desc)

def handle_alert(event):
    event = fix_timestamp(event)
    desc = f"[ALERT] CRITICO: Device {event.get('device_id')} Code: {event.get('error_code')}"
    return safe_insert(event, desc)

def handle_unknown(event):
    event = fix_timestamp(event)
    desc = f"[IGNOTO] Tipo evento non gestito: {event.get('type')}"
    return safe_insert(event, desc)

# Inizializzazione Consumer
consumer = KafkaConsumer(
    *TOPICS,
    bootstrap_servers=KAFKA_BOOTSTRAP,
    security_protocol="SASL_SSL",
    sasl_mechanism="SCRAM-SHA-512",
    sasl_plain_username=SASL_USERNAME,
    sasl_plain_password=SASL_PASSWORD,
    ssl_cafile=KAFKA_CA,
    auto_offset_reset='earliest',
    group_id='iot-consumer-group',
    value_deserializer=lambda v: json.loads(v.decode('utf-8'))
)

print(f"IoT Consumer avviato. In ascolto su: {TOPICS}", flush=True)

# Loop principale
for message in consumer:
    event = message.value
    
    event_type = event.get("type")
    match event_type:
        case "boot":
            handle_boot(event)
        case "telemetry":
            handle_telemetry(event)
        case "firmware_update":
            handle_firmware_update(event)
        case "alert":
            handle_alert(event)
        case _:
            handle_unknown(event)
------------------------------
--- ./Consumer/requirements.txt ---
kafka-python
pymongo
lz4
-----------------------------------
===== FINE Cartella Consumer =====

===== Cartella K8s =====
--- ./K8s/mongodb-config.yaml ---
apiVersion: v1
kind: ConfigMap
metadata:
  name: mongodb-config
  namespace: kafka
data:
  MONGO_HOST: "mongo-mongodb.kafka.svc.cluster.local"
  MONGO_PORT: "27017"
  MONGO_DATABASE: "iot_network"
  MONGO_AUTH_SOURCE: "iot_network"
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: mongodb-config
  namespace: metrics
data:
  MONGO_HOST: "mongo-mongodb.kafka.svc.cluster.local"
  MONGO_PORT: "27017"
  MONGO_DATABASE: "iot_network"
  MONGO_AUTH_SOURCE: "iot_network"
---------------------------------
--- ./K8s/hpa.yaml ---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: producer-hpa
  namespace: kafka
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: producer
  minReplicas: 1
  maxReplicas: 4
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 50   # scala sopra il 50% di CPU media

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: consumer-hpa
  namespace: kafka
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: consumer
  minReplicas: 1
  maxReplicas: 4
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 50

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: metrics-service-hpa
  namespace: metrics
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: metrics-service
  minReplicas: 1
  maxReplicas: 4
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 50

----------------------
--- ./K8s/auth-apikey/apikey-consumer.yaml ---
apiVersion: configuration.konghq.com/v1
kind: KongConsumer
metadata:
  name: iot-devices
  namespace: kafka
  annotations:
    kubernetes.io/ingress.class: kong
    konghq.com/credentials: iot-devices-apikey  # <-- AGGIUNGI QUESTA RIGA
username: iot-devices
----------------------------------------------
--- ./K8s/auth-apikey/apikey-credential.yaml ---
apiVersion: v1
kind: Secret
metadata:
  name: iot-devices-apikey
  namespace: kafka
  labels:
    konghq.com/credential: key-auth
stringData:
  key: "iot-sensor-key-prod-v1"
  # In produzione: generare con `openssl rand -hex 32`
------------------------------------------------
--- ./K8s/auth-apikey/apikey-plugin-kafka.yaml ---
apiVersion: configuration.konghq.com/v1
kind: KongPlugin
metadata:
  name: key-auth
  namespace: kafka
plugin: key-auth
config:
  key_names:
    - apikey
  hide_credentials: true
--------------------------------------------------
--- ./K8s/auth-apikey/apikey-credential-metrics.yaml ---
apiVersion: v1
kind: Secret
metadata:
  name: iot-devices-apikey
  namespace: metrics
  labels:
    konghq.com/credential: key-auth
stringData:
  key: "iot-sensor-key-prod-v1"
--------------------------------------------------------
--- ./K8s/auth-apikey/apikey-plugin-metrics.yaml ---
apiVersion: configuration.konghq.com/v1
kind: KongPlugin
metadata:
  name: key-auth
  namespace: metrics
plugin: key-auth
config:
  key_names:
    - apikey
  hide_credentials: true
----------------------------------------------------
--- ./K8s/kafka/kafka-cluster.yaml ---
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaNodePool
metadata:
  name: controller
  namespace: kafka
  labels:
    strimzi.io/cluster: iot-sensor-cluster
spec:
  replicas: 2 #per HA Assicura che i metadati del cluster (gestiti da Kraft) siano disponibili anche se 1 controller su 3 fallisce.
  roles:
    - controller
  storage:
    type: jbod
    volumes:
      - id: 0
        type: persistent-claim
        size: 5Gi
        kraftMetadata: shared
        deleteClaim: false
---
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaNodePool
metadata:
  name: broker
  namespace: kafka
  labels:
    strimzi.io/cluster: iot-sensor-cluster
spec:
  replicas: 2 #per HA Consente ai client di connettersi ad altri broker se uno fallisce.
  roles:
    - broker
  storage:
    type: jbod
    volumes:
      - id: 0
        type: persistent-claim
        size: 5Gi
        kraftMetadata: shared
        deleteClaim: false
---
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: iot-sensor-cluster
  namespace: kafka
spec:
  kafka:
    version: 4.1.0
    metadataVersion: 4.1-IV1
    listeners:
      - name: plain
        port: 9092
        type: internal
        tls: false
      - name: tls
        port: 9093
        type: internal
        tls: true
        authentication:
          type: scram-sha-512
    config:
    #Garantisce che 3 copie di ogni partizione esistano e che almeno 2 siano sincronizzate. Se 1 broker fallisce, la scrittura può continuare verso le 2 rimanenti senza perdere dati.
      # Aumenta il fattore di replicazione a 3
      offsets.topic.replication.factor: 2
      transaction.state.log.replication.factor: 2
      default.replication.factor: 2 # Fattore di replicazione per i nuovi topic
      
      # Minimo di In-Sync Replicas (HA/Durabilità)
      # Il valore di 2 significa che 1 replica può fallire e il sistema resta disponibile (3-1=2)
      transaction.state.log.min.isr: 1 
      min.insync.replicas: 1
  entityOperator:
    topicOperator: {}
    userOperator: {}

--------------------------------------
--- ./K8s/kafka/kafka-topics.yaml ---
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: sensor-telemetry
  namespace: kafka
  labels:
    strimzi.io/cluster: iot-sensor-cluster
spec:
  partitions: 3
  replicas: 2
  config:
    retention.ms: 604800000   # 7 giorni
    segment.bytes: 1073741824 # 1GB
    compression.type: lz4      # Compressione per alto volume
---
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: sensor-alerts
  namespace: kafka
  labels:
    strimzi.io/cluster: iot-sensor-cluster
spec:
  partitions: 2
  replicas: 2
  config:
    retention.ms: 2592000000  # 30 giorni (più lungo per audit)
    segment.bytes: 536870912  # 512MB
    min.insync.replicas: 2    # Maggiore durabilità per dati critici
-------------------------------------
--- ./K8s/kafka/kafka-users.yaml ---
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaUser
metadata:
  name: producer-user
  namespace: kafka
  labels:
    strimzi.io/cluster: iot-sensor-cluster
spec:
  authentication:
    type: scram-sha-512
---
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaUser
metadata:
  name: consumer-user
  namespace: kafka
  labels:
    strimzi.io/cluster: iot-sensor-cluster
spec:
  authentication:
    type: scram-sha-512
------------------------------------
--- ./K8s/micro-services/consumer-deployment.yaml ---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: consumer
  namespace: kafka
spec:
  replicas: 1
  selector:
    matchLabels:
      app: consumer
  template:
    metadata:
      labels:
        app: consumer
    spec:
      containers:
      - name: consumer
        image: consumer:latest
        imagePullPolicy: IfNotPresent
        env:
        - name: KAFKA_BOOTSTRAP
          value: "iot-sensor-cluster-kafka-bootstrap.kafka.svc.cluster.local:9093"
        - name: SASL_USERNAME
          value: "consumer-user"
        - name: SASL_PASSWORD
          valueFrom:
            secretKeyRef:
              name: consumer-user
              key: password
        - name: KAFKA_CA
          value: "/etc/ssl/certs/kafka/ca.crt"
        # MongoDB Config da ConfigMap
        - name: MONGO_HOST
          valueFrom:
            configMapKeyRef:
              name: mongodb-config
              key: MONGO_HOST
        - name: MONGO_PORT
          valueFrom:
            configMapKeyRef:
              name: mongodb-config
              key: MONGO_PORT
        - name: MONGO_DATABASE
          valueFrom:
            configMapKeyRef:
              name: mongodb-config
              key: MONGO_DATABASE
        - name: MONGO_AUTH_SOURCE
          valueFrom:
            configMapKeyRef:
              name: mongodb-config
              key: MONGO_AUTH_SOURCE
        # MongoDB Credentials da Secret
        - name: MONGO_USER
          valueFrom:
            secretKeyRef:
              name: mongo-creds
              key: MONGO_USER
        - name: MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mongo-creds
              key: MONGO_PASSWORD
        volumeMounts:
        - name: kafka-ca
          mountPath: /etc/ssl/certs/kafka
          readOnly: true
        resources:
          requests:
            cpu: "100m"
            memory: "128Mi"
          limits:
            cpu: "500m"
            memory: "256Mi"
      volumes:
      - name: kafka-ca
        secret:
          secretName: kafka-ca-cert
-----------------------------------------------------
--- ./K8s/micro-services/producer-ingress.yaml ---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: producer-ingress
  namespace: kafka
  annotations:
    konghq.com/plugins: key-auth  # <--- CAMBIATO: da jwt-auth a key-auth
spec:
  ingressClassName: kong  
  rules:
  - host: producer.192.168.58.2.nip.io  # NOTA: Assicurati che l'IP sia quello del tuo minikube ip
    http:
      paths:
        - path: /event
          pathType: Prefix
          backend:
            service:
              name: producer-service
              port:
                number: 5000
--------------------------------------------------
--- ./K8s/micro-services/metrics-ingress.yaml ---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: metrics-ingress
  namespace: metrics
  annotations:
    konghq.com/plugins: key-auth  # <--- CAMBIATO: da jwt-auth a key-auth
spec:
  ingressClassName: kong
  rules:
    - host: metrics.192.168.58.2.nip.io # NOTA: Verifica IP
      http:
        paths:
          - path: /metrics
            pathType: Prefix
            backend:
              service:
                name: metrics-service
                port:
                  number: 5001
-------------------------------------------------
--- ./K8s/micro-services/metrics-deployment.yaml ---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: metrics-service
  namespace: metrics
spec:
  replicas: 1
  selector:
    matchLabels:
      app: metrics-service
  template:
    metadata:
      labels:
        app: metrics-service
    spec:
      containers:
      - name: metrics-service
        image: metrics-service:latest
        imagePullPolicy: IfNotPresent
        env:
        # MongoDB Config da ConfigMap
        - name: MONGO_HOST
          valueFrom:
            configMapKeyRef:
              name: mongodb-config
              key: MONGO_HOST
        - name: MONGO_PORT
          valueFrom:
            configMapKeyRef:
              name: mongodb-config
              key: MONGO_PORT
        - name: MONGO_DATABASE
          valueFrom:
            configMapKeyRef:
              name: mongodb-config
              key: MONGO_DATABASE
        - name: MONGO_AUTH_SOURCE
          valueFrom:
            configMapKeyRef:
              name: mongodb-config
              key: MONGO_AUTH_SOURCE
        # MongoDB Credentials da Secret
        - name: MONGO_USER
          valueFrom:
            secretKeyRef:
              name: mongo-creds
              key: MONGO_USER
        - name: MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mongo-creds
              key: MONGO_PASSWORD
        ports:
        - containerPort: 5001
        resources:
          requests:
            cpu: "100m"
            memory: "128Mi"
          limits:
            cpu: "500m"
            memory: "256Mi"
---
apiVersion: v1
kind: Service
metadata:
  name: metrics-service
  namespace: metrics
spec:
  selector:
    app: metrics-service
  ports:
    - protocol: TCP
      port: 5001
      targetPort: 5001
  type: ClusterIP
----------------------------------------------------
--- ./K8s/micro-services/producer-deployment.yaml ---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: producer
  namespace: kafka
spec:
  replicas: 1
  selector:
    matchLabels:
      app: producer
  template:
    metadata:
      labels:
        app: producer
    spec:
      containers:
      - name: producer
        image: producer:latest
        imagePullPolicy: IfNotPresent
        env:
        - name: KAFKA_BOOTSTRAP
          value: "iot-sensor-cluster-kafka-bootstrap.kafka.svc.cluster.local:9093"
        - name: SASL_USERNAME
          value: "producer-user"
        - name: SASL_PASSWORD
          valueFrom:
            secretKeyRef:
              name: producer-user
              key: password
        - name: KAFKA_CA
          value: "/etc/ssl/certs/kafka/ca.crt"
        ports:
        - containerPort: 5000
        volumeMounts:
        - name: kafka-ca
          mountPath: /etc/ssl/certs/kafka
          readOnly: true
        resources:
          requests:
            cpu: "100m"
            memory: "128Mi"
          limits:
            cpu: "500m"
            memory: "256Mi"
      volumes:
      - name: kafka-ca
        secret:
          secretName: kafka-ca-cert
---
apiVersion: v1
kind: Service
metadata:
  name: producer-service
  namespace: kafka
spec:
  selector:
    app: producer
  ports:
  - protocol: TCP
    port: 5000
    targetPort: 5000
  type: ClusterIP
-----------------------------------------------------
===== FINE Cartella K8s =====

===== Cartella Metrics-service =====
--- ./Metrics-service/metrics_service.py ---
from flask import Flask, jsonify
from pymongo import MongoClient
from datetime import datetime, timedelta
import os

app = Flask(__name__)

# Configurazione MongoDB da ConfigMap e Secret
MONGO_HOST = os.getenv("MONGO_HOST")
MONGO_PORT = os.getenv("MONGO_PORT")
MONGO_DATABASE = os.getenv("MONGO_DATABASE")
MONGO_USER = os.getenv("MONGO_USER")
MONGO_PASSWORD = os.getenv("MONGO_PASSWORD")
MONGO_AUTH_SOURCE = os.getenv("MONGO_AUTH_SOURCE")

MONGO_URI = f"mongodb://{MONGO_USER}:{MONGO_PASSWORD}@{MONGO_HOST}:{MONGO_PORT}/{MONGO_DATABASE}?authSource={MONGO_AUTH_SOURCE}"

client = MongoClient(MONGO_URI)
db = client[MONGO_DATABASE]
collection = db.sensor_data

# Test di connessione
try:
    client.admin.command('ping')
    print("Connected to MongoDB (IoT Network)")
except Exception as e:
    print(f"MongoDB connection error: {e}")

# 1. Totale Avvii (Boot Events)
@app.route("/metrics/boots", methods=["GET"])
def total_boots():
    count = collection.count_documents({"type": "boot"})
    return jsonify({"total_device_boots": count})

# 2. Media Temperatura per Zona
@app.route("/metrics/temperature/average-by-zone", methods=["GET"])
def avg_temp_per_zone():
    pipeline = [
        {"$match": {"type": "telemetry"}},
        {"$group": {
            "_id": "$zone_id", 
            "avg_temp": {"$avg": "$temperature"},
            "avg_hum": {"$avg": "$humidity"},
            "samples": {"$sum": 1}
        }}
    ]
    result = list(collection.aggregate(pipeline))
    return jsonify(result)

# 3. Conta Allarmi Critici
@app.route("/metrics/alerts", methods=["GET"])
def critical_alerts():
    pipeline = [
        {"$match": {"type": "alert"}},
        {"$group": {"_id": "$severity", "count": {"$sum": 1}}}
    ]
    result = list(collection.aggregate(pipeline))
    return jsonify(result)

# 4. Trend Attività ultimi 7 giorni
@app.route("/metrics/activity/last7days", methods=["GET"])
def activity_trend():
    since = datetime.utcnow() - timedelta(days=7)
    pipeline = [
        {"$match": {"_ingest_ts": {"$gte": since}}},
        {"$group": {
            "_id": {"$dateToString": {"format": "%Y-%m-%d", "date": "$_ingest_ts"}}, 
            "events_count": {"$sum": 1}
        }},
        {"$sort": {"_id": 1}}
    ]
    result = list(collection.aggregate(pipeline))
    return jsonify(result)

# 5. Stato Firmware
@app.route("/metrics/firmware", methods=["GET"])
def firmware_stats():
    pipeline = [
        {"$match": {"type": "firmware_update"}},
        {"$group": {"_id": "$update_to", "count": {"$sum": 1}}}
    ]
    result = list(collection.aggregate(pipeline))
    return jsonify(result)

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5001)
--------------------------------------------
--- ./Metrics-service/Dockerfile ---
FROM python:3.11-slim

WORKDIR /app

COPY metrics_service.py requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt

CMD ["python", "metrics_service.py"]

------------------------------------
--- ./Metrics-service/requirements.txt ---
flask
pymongo
------------------------------------------
===== FINE Cartella Metrics-service =====

===== Cartella Producer =====
--- ./Producer/Dockerfile ---
FROM python:3.11-slim

WORKDIR /app
COPY producer.py requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt

EXPOSE 5000

CMD ["python", "producer.py"]

-----------------------------
--- ./Producer/requirements.txt ---
kafka-python
flask
-----------------------------------
--- ./Producer/producer.py ---
from flask import Flask, request, jsonify
from kafka import KafkaProducer
import json, os, uuid
from datetime import datetime

app = Flask(__name__)

# Configurazione da ConfigMap e Secret
KAFKA_BOOTSTRAP = os.getenv("KAFKA_BOOTSTRAP")
SASL_USERNAME = os.getenv("SASL_USERNAME")
SASL_PASSWORD = os.getenv("SASL_PASSWORD")
KAFKA_CA = os.getenv("KAFKA_CA", "/etc/ssl/certs/kafka/ca.crt")

# Topic Kafka
TOPIC_TELEMETRY = "sensor-telemetry"
TOPIC_ALERTS = "sensor-alerts"

# Kafka Secure Producer
producer = KafkaProducer(
    bootstrap_servers=KAFKA_BOOTSTRAP,
    security_protocol="SASL_SSL",
    sasl_mechanism="SCRAM-SHA-512",
    sasl_plain_username=SASL_USERNAME,
    sasl_plain_password=SASL_PASSWORD,
    ssl_cafile=KAFKA_CA,
    value_serializer=lambda v: json.dumps(v).encode("utf-8")
)

# Contatori Locali
event_count = {
    "boot": 0,
    "telemetry": 0,
    "firmware_update": 0,
    "alert": 0
}

def produce_event(topic: str, event_type: str, payload: dict):
    """Invia evento IoT a Kafka sul topic appropriato"""
    event = {
        "event_id": str(uuid.uuid4()),
        "type": event_type,
        "timestamp": datetime.utcnow().isoformat(),
        **payload
    }
    producer.send(topic, value=event)
    producer.flush()
    
    if event_type in event_count:
        event_count[event_type] += 1
        
    print(f"[PRODUCER] {event_type} -> {topic}: {event}", flush=True)
    return event


# 1. Device Boot (Telemetry Topic)
@app.route("/event/boot", methods=["POST"])
def device_boot():
    data = request.json or {}
    required = ["device_id", "zone_id"] 
    if not all(k in data for k in required):
        return jsonify({"error": f"Missing fields: {required}"}), 400

    event = produce_event(TOPIC_TELEMETRY, "boot", {
        "device_id": data["device_id"],
        "zone_id": data["zone_id"],
        "firmware": data.get("firmware", "unknown")
    })
    return jsonify({"status": "boot_recorded", "event": event}), 200

# 2. Telemetry Data (Telemetry Topic)
@app.route("/event/telemetry", methods=["POST"])
def telemetry():
    data = request.json or {}
    required = ["device_id", "temperature", "humidity", "zone_id"]
    if not all(k in data for k in required):
        return jsonify({"error": f"Missing fields: {required}"}), 400

    event = produce_event(TOPIC_TELEMETRY, "telemetry", {
        "device_id": data["device_id"],
        "zone_id": data["zone_id"],
        "temperature": float(data["temperature"]),
        "humidity": float(data["humidity"])
    })
    return jsonify({"status": "data_received", "event": event}), 200

# 3. Firmware Update (Telemetry Topic)
@app.route("/event/firmware_update", methods=["POST"])
def firmware_update():
    data = request.json or {}
    required = ["device_id", "version_to"]
    if not all(k in data for k in required):
        return jsonify({"error": f"Missing fields: {required}"}), 400

    event = produce_event(TOPIC_TELEMETRY, "firmware_update", {
        "device_id": data["device_id"],
        "update_to": data["version_to"]
    })
    return jsonify({"status": "update_started", "event": event}), 200

# 4. Critical Alert (Alerts Topic)
@app.route("/event/alert", methods=["POST"])
def alert():
    data = request.json or {}
    required = ["device_id", "error_code", "severity"]
    if not all(k in data for k in required):
        return jsonify({"error": f"Missing fields: {required}"}), 400

    event = produce_event(TOPIC_ALERTS, "alert", {
        "device_id": data["device_id"],
        "error_code": data["error_code"],
        "severity": data["severity"]
    })
    return jsonify({"status": "alert_logged", "event": event}), 200

# Metriche interne
@app.route("/metrics", methods=["GET"])
def metrics():
    total = sum(event_count.values())
    return jsonify({"iot_events_sent": total, "breakdown": event_count}), 200

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
------------------------------
===== FINE Cartella Producer =====
